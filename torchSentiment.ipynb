{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B0lN-RoK5bv",
        "outputId": "8249cf8f-d3cf-493e-f6c9-6e40bc193a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Movie-Review-Sentiment-Analysis-LSTM-Pytorch'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 36 (delta 0), reused 0 (delta 0), pack-reused 33\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lukysummer/Movie-Review-Sentiment-Analysis-LSTM-Pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdp_xdOLL0uo",
        "outputId": "a95bd6ce-d8d4-4290-a726-f200c85073e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels.txt  reviews.txt\n"
          ]
        }
      ],
      "source": [
        "!ls Movie-Review-Sentiment-Analysis-LSTM-Pytorch/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mcrcB2ovK1IQ"
      },
      "outputs": [],
      "source": [
        "with open(\"Movie-Review-Sentiment-Analysis-LSTM-Pytorch/data/reviews.txt\") as f:\n",
        "    reviews = f.read()\n",
        "    \n",
        "with open(\"Movie-Review-Sentiment-Analysis-LSTM-Pytorch/data/labels.txt\") as f:\n",
        "    labels = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xqjDiBxuK1Iw"
      },
      "outputs": [],
      "source": [
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UcDXBfM6K1I5"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([ch for ch in text if ch not in punctuation])\n",
        "    all_reviews = text.split(\"\\n\")\n",
        "    text = \" \".join(text)\n",
        "    all_words = text.split()\n",
        "    \n",
        "    return all_reviews, all_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yRXfxUXVK1JB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eMrSD-g4K1JJ"
      },
      "outputs": [],
      "source": [
        "all_reviews, all_words = preprocess(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AxxQYnOqK1JR"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "brVAT3hNK1JZ"
      },
      "outputs": [],
      "source": [
        "word_counts = Counter(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uibuq0BK1Ji",
        "outputId": "64b59cad-38ad-48c6-ab46-5bc684344c7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'b': 515850,\n",
              "         'r': 1550946,\n",
              "         'o': 1922852,\n",
              "         'm': 709785,\n",
              "         'w': 509705,\n",
              "         'e': 3086458,\n",
              "         'l': 1143358,\n",
              "         ' ': 7434318,\n",
              "         'h': 1408705,\n",
              "         'i': 1984336,\n",
              "         'g': 537842,\n",
              "         's': 1754598,\n",
              "         'a': 2082813,\n",
              "         'c': 720691,\n",
              "         't': 2420932,\n",
              "         'n': 1705883,\n",
              "         'd': 906473,\n",
              "         'y': 533174,\n",
              "         '.': 327192,\n",
              "         'p': 441581,\n",
              "         'u': 687982,\n",
              "         'f': 572095,\n",
              "         'v': 326565,\n",
              "         'k': 223823,\n",
              "         'x': 43360,\n",
              "         '\\n': 25000,\n",
              "         'z': 23095,\n",
              "         'j': 58707,\n",
              "         'q': 20148})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EM48ASOLK1Jt"
      },
      "outputs": [],
      "source": [
        "word_list = sorted(word_counts, key = word_counts.get, reverse = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lQw4NozISf68"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6UEjmQLmK1J_"
      },
      "outputs": [],
      "source": [
        "vocab_to_int = {word:idx for idx, word in enumerate(word_list)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N159tnZK1KH",
        "outputId": "35aeaaa4-52b1-4ea1-9431-fb728df4943c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'e': 1,\n",
              " 't': 2,\n",
              " 'a': 3,\n",
              " 'i': 4,\n",
              " 'o': 5,\n",
              " 's': 6,\n",
              " 'n': 7,\n",
              " 'r': 8,\n",
              " 'h': 9,\n",
              " 'l': 10,\n",
              " 'd': 11,\n",
              " 'c': 12,\n",
              " 'm': 13,\n",
              " 'u': 14,\n",
              " 'f': 15,\n",
              " 'g': 16,\n",
              " 'y': 17,\n",
              " 'b': 18,\n",
              " 'w': 19,\n",
              " 'p': 20,\n",
              " '.': 21,\n",
              " 'v': 22,\n",
              " 'k': 23,\n",
              " 'j': 24,\n",
              " 'x': 25,\n",
              " '\\n': 26,\n",
              " 'z': 27,\n",
              " 'q': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "vocab_to_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NMyQ2MDrK1KS"
      },
      "outputs": [],
      "source": [
        "int_to_vocab = {idx:word for word, idx in vocab_to_int.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5kuUX_SK1KZ",
        "outputId": "1efc2d3d-07b5-4745-b782-8f5519b22450"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: 'e',\n",
              " 2: 't',\n",
              " 3: 'a',\n",
              " 4: 'i',\n",
              " 5: 'o',\n",
              " 6: 's',\n",
              " 7: 'n',\n",
              " 8: 'r',\n",
              " 9: 'h',\n",
              " 10: 'l',\n",
              " 11: 'd',\n",
              " 12: 'c',\n",
              " 13: 'm',\n",
              " 14: 'u',\n",
              " 15: 'f',\n",
              " 16: 'g',\n",
              " 17: 'y',\n",
              " 18: 'b',\n",
              " 19: 'w',\n",
              " 20: 'p',\n",
              " 21: '.',\n",
              " 22: 'v',\n",
              " 23: 'k',\n",
              " 24: 'j',\n",
              " 25: 'x',\n",
              " 26: '\\n',\n",
              " 27: 'z',\n",
              " 28: 'q'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "int_to_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iLbbtZQvK1Ki"
      },
      "outputs": [],
      "source": [
        "encoded_reviews = [[vocab_to_int[word] for word in review] for review in all_reviews]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SabhkmGbK1Ko"
      },
      "outputs": [],
      "source": [
        "# encoded_reviews = []\n",
        "# i = 0\n",
        "# for review in all_reviews:\n",
        "#     curr_rev = []\n",
        "#     for letter in review:\n",
        "#         if letter==\" \":\n",
        "#             continue\n",
        "#         curr_rev.append(vocab_to_int[letter])\n",
        "#     encoded_reviews.append(letter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "peH1RpxSSf8D"
      },
      "outputs": [],
      "source": [
        "all_labels = labels.split(\"\\n\")\n",
        "encoded_labels = [1 if label == \"positive\" else 0 for label in all_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOGaflCGSf8K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoH8K0_OK1LX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaVxnxjLK1Lg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anFffKx-K1Ln"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzfXNCyFK1Lr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMDSO1TuK1Ly"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nCHVhnPK1L3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xBC5b1RK1L7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKjvNNU-K1MD",
        "outputId": "8ddef20a-3248-4a9d-b07f-a2f4e56b5e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /Users/Pratik/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT4jrjSOK1MJ",
        "outputId": "6ecf455a-efef-4e21-f5ee-98f4eaea1bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/Pratik/opt/anaconda3/lib/python3.9/site-packages (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/Pratik/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u_bCir_jK1MP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qCRMDXK4K1MW"
      },
      "outputs": [],
      "source": [
        "encoded_labels = np.array( [label for idx, label in enumerate(encoded_labels) if len(encoded_reviews[idx]) > 0] )\n",
        "encoded_reviews = [review for review in encoded_reviews if len(review) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_bDYLJ63Sf9i"
      },
      "outputs": [],
      "source": [
        "def pad_text(encoded_reviews, seq_length):\n",
        "    \n",
        "    reviews = []\n",
        "    \n",
        "    for review in encoded_reviews:\n",
        "        if len(review) >= seq_length:\n",
        "            reviews.append(review[:seq_length])\n",
        "        else:\n",
        "            reviews.append([0]*(seq_length-len(review)) + review)\n",
        "        \n",
        "    return np.array(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YnQOJ0oFSf9m"
      },
      "outputs": [],
      "source": [
        "padded_reviews = pad_text(encoded_reviews, seq_length = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WlRBb5LuSf9r"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.8\n",
        "valid_ratio = (1 - train_ratio)/2\n",
        "total = padded_reviews.shape[0]\n",
        "train_cutoff = int(total * train_ratio)\n",
        "valid_cutoff = int(total * (1 - valid_ratio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bbe10saKSf9v"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = padded_reviews[:train_cutoff], encoded_labels[:train_cutoff]\n",
        "valid_x, valid_y = padded_reviews[train_cutoff : valid_cutoff], encoded_labels[train_cutoff : valid_cutoff]\n",
        "test_x, test_y   = padded_reviews[valid_cutoff:], encoded_labels[valid_cutoff:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "10hPTqWiSf90"
      },
      "outputs": [],
      "source": [
        "train_x = torch.Tensor(train_x).type(torch.LongTensor)\n",
        "train_y = torch.Tensor(train_y).type(torch.LongTensor)\n",
        "valid_x = torch.Tensor(valid_x).type(torch.LongTensor)\n",
        "valid_y = torch.Tensor(valid_y).type(torch.LongTensor)\n",
        "test_x  = torch.Tensor(test_x).type(torch.LongTensor)\n",
        "test_y  = torch.Tensor(test_y).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TDxdReYtSf94"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nBibCl5PSf99"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(train_x, train_y)\n",
        "valid_data = TensorDataset(valid_x, valid_y)\n",
        "test_data = TensorDataset(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "h6b6KPT2Sf-C"
      },
      "outputs": [],
      "source": [
        "batch_size = 25\n",
        "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gS8e2pSrSf-F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Pqy6BB-iSf-I"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MiCx4JQuSf-N"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z83iHlrISf-R"
      },
      "outputs": [],
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.5):\n",
        "        super().__init__()\n",
        "        # params: \"n_\" means dimension\n",
        "        self.n_vocab = n_vocab     # number of unique words in vocabulary\n",
        "        self.n_layers = n_layers   # number of LSTM layers \n",
        "        self.n_hidden = n_hidden   # number of hidden nodes in LSTM\n",
        "        \n",
        "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
        "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\n",
        "        self.dropout = nn.Dropout(drop_p)\n",
        "        self.fc = nn.Linear(n_hidden, n_output)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward (self, input_words, h):\n",
        "        \n",
        "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
        "        lstm_out, h = self.lstm(embedded_words, h)         # (batch_size, seq_length, n_hidden)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden) # (batch_size*seq_length, n_hidden)\n",
        "        fc_out = self.fc(lstm_out)                      # (batch_size*seq_length, n_output)\n",
        "        sigmoid_out = self.sigmoid(fc_out)              # (batch_size*seq_length, n_output)\n",
        "        sigmoid_out = sigmoid_out.view(batch_size, -1)  # (batch_size, seq_length*n_output)\n",
        "        \n",
        "        # extract the output of ONLY the LAST output of the LAST element of the sequence\n",
        "        sigmoid_last = sigmoid_out[:, -1]               # (batch_size, 1)\n",
        "        \n",
        "        return sigmoid_last, h\n",
        "    \n",
        "    \n",
        "    def init_hidden (self, batch_size):  # initialize hidden weights (h,c) to 0\n",
        "        \n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        device = \"cpu\"\n",
        "        weights = next(self.parameters()).data\n",
        "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "        \n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gW38odl0Sf-U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jMQsazLwSf-Z"
      },
      "outputs": [],
      "source": [
        "n_vocab = len(vocab_to_int)+1\n",
        "n_embed = 400\n",
        "n_hidden = 512\n",
        "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "G_Pt-RypSf-e"
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRxp5lqDY1AV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "GCK_b4u_Sf-i"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "bEa7uLkMSf-o"
      },
      "outputs": [],
      "source": [
        "print_every = 100\n",
        "step = 0\n",
        "n_epochs = 4  # validation loss increases from ~ epoch 3 or 4\n",
        "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMW2O-6fSf-r"
      },
      "outputs": [],
      "source": [
        "for epoch in range(n_epochs):\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # making requires_grad = False for the latest set of h\n",
        "        h = tuple([each.data for each in h])   \n",
        "        \n",
        "        net.zero_grad()\n",
        "        output, h = net(inputs)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (step % print_every) == 0:            \n",
        "            ######################\n",
        "            ##### VALIDATION #####\n",
        "            ######################\n",
        "            net.eval()\n",
        "            valid_losses = []\n",
        "            v_h = net.init_hidden(batch_size)\n",
        "            \n",
        "            for v_inputs, v_labels in valid_loader:\n",
        "                v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "                v_h = tuple([each.data for each in v_h])\n",
        "                \n",
        "                v_output, v_h = net(v_inputs)\n",
        "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
        "                valid_losses.append(v_loss.item())\n",
        "\n",
        "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
        "                  \"Step: {}\".format(step),\n",
        "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
        "                  \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
        "            net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx48fvadSf-u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv4xyxnVSf-x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH4jD8drSf-2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjvRlg77Sf--"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuj95Ep3Sf_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AoQNS56Sf_D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApP4BSWHSf_J"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "test_h = net.init_hidden(batch_size)\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "    test_output, test_h = net(inputs, test_h)\n",
        "    loss = criterion(test_output, labels)\n",
        "    test_losses.append(loss.item())\n",
        "    \n",
        "    preds = torch.round(test_output.squeeze())\n",
        "    correct_tensor = preds.eq(labels.float().view_as(preds))\n",
        "    correct = np.squeeze(correct_tensor.numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    \n",
        "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
        "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fDbyUSkSf_M"
      },
      "outputs": [],
      "source": [
        "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
        "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyHxtzBRSf_R"
      },
      "outputs": [],
      "source": [
        "words = preprocess(\"It made me cry.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ2WHMKdSf_U"
      },
      "outputs": [],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_R8R4G4Sf_X"
      },
      "outputs": [],
      "source": [
        "encoded_words = [vocab_to_int[word] for word in words[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1VvtR_oSf_b"
      },
      "outputs": [],
      "source": [
        "def predict(net, review, seq_length = 200):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    device = \"cpu\"\n",
        "    words = preprocess(review)\n",
        "    encoded_words = [vocab_to_int[word] for word in words[1]]\n",
        "    padded_words = pad_text([encoded_words], seq_length)\n",
        "    padded_words = torch.from_numpy(padded_words).to(device)\n",
        "    \n",
        "    if(len(padded_words) == 0):\n",
        "        \"Your review must contain at least 1 word!\"\n",
        "        return None\n",
        "    \n",
        "    net.eval()\n",
        "    h = net.init_hidden(1)\n",
        "    output, h = net(padded_words, h)\n",
        "    pred = (output.squeeze())\n",
        "    msg = \"This is a positive review.\" if pred[0] == 0 else \"This is a negative review.\"\n",
        "    \n",
        "    return msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN-kOU13Sf_e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVmw7tkBSf_h",
        "outputId": "e1597a4f-951b-4de9-c2fd-4fbc43850985"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'This is a negative review.'"
            ]
          },
          "execution_count": 81,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review1 = \"It made me cry.\"\n",
        "predict(net, review1)  ## negative ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Vp_FH3Sf_k",
        "outputId": "ba20990a-f3b6-48d4-d843-105d9d6f4161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'This is a negative review.'"
            ]
          },
          "execution_count": 82,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review2 = \"It was so good it made me cry.\"\n",
        "predict(net, review2)  ## positive ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmHhXD29Sf_n"
      },
      "outputs": [],
      "source": [
        "review3 = \"It's ok.\"\n",
        "predict(net, review3)  ## negative ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gPl5KRGSf_p"
      },
      "outputs": [],
      "source": [
        "review4 = \"This movie had the best acting and the dialogue was so good. I loved it.\"\n",
        "predict(net, review4)  ## positive ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAfATyjbSf_s"
      },
      "outputs": [],
      "source": [
        "review5 = \"Garbage\"\n",
        "predict(net, review5)  ## negative ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLfm8385Sf_u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbrj76-nSf_w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}